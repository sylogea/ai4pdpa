\chapter{Literature Review}

\lipsum[1-5]

% \paragraph{Personal Data Protection in Singapore.}

% Rapid digitalization has increased the scale at which organizations collect and process personal data, making data protection a key concern, especially in Singapore (Zul, 2022). The growing reliance on technologies and artificial intelligence results in the need for a clear governance framework to manage the collection, use, and disposal of personal data responsibly (Schubert and Barrett, 2024). As digital services expand across different industries, the risk of data misuse, unauthorized access and breaches has also grown (KPMG, 2023).

% In response to these challenges, PDPA was established to safeguard individual's personal data while supporting organizations' business interest (PDPA Overview, n.d.). To aid compliance, PDPC uploads advisory guidelines to aid organizations and individuals in their understanding of PDPA (Advisory Guidelines on Key Concepts in the Personal Data Protection Act, n.d.).

% However, despite the availability of these resources, many organizations and individuals struggle to understand and comply with PDPA requirements correctly due to constant evolving regulations (Key Challenges in Achieving PDPA Compliance in 2024, 2024). According to the PDPC's 2015 industry survey, about 58\% of organizations required support to achieve compliance, reflecting knowledge and resource gaps (Industry Survey on the Personal Data Protection Act September 2015, 2015). This suggests that as innovative technologies and regulations emerge, traditional resources may not be sufficient for compliance support. Also, there is growing interest in leveraging artificial intelligence (AI) to automate retrieval of knowledge and comprehension of regulatory compliance (Gültekin-Várkonyi*, 2025). Hence, there is an opportunity to combine AI and compliance to create tools that can interpret legal frameworks and make regulatory knowledge more accessible.

% \paragraph{Compliance Challenges for Small and Medium Enterprises.}

% Small and medium enterprises (SMEs) form the backbone of Singapore economy, accounting over 99\% of all enterprises and employing 70\% of the workforce (Lim, 2025). However, SMEs often face greater obstacles in meeting compliance requirements compared to larger organizations due to limited finance resources and the growing complexity of regulatory obligations (Bello, Idemudia, and Iyelolu, 2024).

% Because SMEs must prioritize day-to-day operations and revenue generation, compliance is viewed as a secondary priority. Hence, many do not allocate sufficient time, budget, or staff to interpret and implement compliance regulations (Common Regulatory Compliance Challenges for SMEs, 2025).
% Digital capability gaps further worsen the compliance challenge. According to a survey conducted by Capterra, 32\% of SMEs still rely on spreadsheets to manage customer's information, while another 35\% uses manual methods or email communication, which are insufficient under modern data protection guidelines (Navarrete, 2019). These informal or decentralized data management methods make it difficult to track consent, update records accurately, or ensure secure retention and disposal.

% In this context, there is a clear need for accessible, low-barrier compliance support tools tailored to SMEs. Solutions such as AI-drive PDPA chatbots can lower the knowledge and resource barrier by providing SMEs with immediate, accurate guidance without requiring legal expertise, formal training, or expensive consultancy services.

% \paragraph{Existing PDPA Compliance Tools and Their Limitations.}

% A variety of resources are available to support PDPA compliance, primarily provided by PDPC. These include advisory guidelines, compliance checklists, assessment tools, and the Data Protection Essentials programmer for SMEs (Kick-starting Your Data Protection Journey, n.d.). Although these materials are comprehensive, they are spread across multiple documents and written in technically dense language, making them challenging non-experts to navigate efficiently. During the team's review of these materials, it became clear that users often struggle to identify which specific sections apply to their situation or to interpret PDPA requirements without legal or technical expertise (A.M. Lonzetta and Hayajneh, 2020).

% In addition to PDPC materials, several commercial and professional solutions are available. Many organizations engage outsourced Data Protection Officers or legal consultants to interpret PDPA requirements on their behalf. Others adopt enterprise-grade privacy management systems such as Varonis or Verasafe, which offer data governance dashboards and risk assessment modules. However, they are costly, require ongoing subscription fees which are impractical for SMEs with limited budgets. For example, Onspring's privacy management software costs approximately \$30 000 to \$56,000 for initial setup with annual subscription fees ranging from \$10 000 to \$50 000 (Randall, 2025). Furthermore, existing solutions lack conversational, real-time interaction. Users must manually search through documentation, navigate dashboards, or rely on external consultants.

% Taken together, these findings highlight the absence of an accessible, affordable, and PDPA-specific digital tool capable of providing real-time compliance support. This gap underscores the need for an AI-powered PDPA chatbot that allows users to obtain accurate, scenario-specific guidance without requiring legal expertise or substantial financial investment.

% \paragraph{AI and Chatbots for Legal and Compliance Support.}

% The increasing complexity of legal and regulatory frameworks has driven organizations to adopt AI solutions to automate and streamline compliance processes (Bleach, 2024). AI technologies such as natural language processing (NLP) and large language models (LLMs) allow systems to interpret, analyze, and generate human-like responses to text-based queries (Vaniukov, 2024). In the legal industry, AI tools are being used for document analysis, legal advice support, and contract drafting, reducing mundane works and improving efficiency (What Is Legal Artificial Intelligence (AI) And How Will It Affect The Next Generation Of Legal Professionals?, n.d.).

% A key innovation in this area is AI chatbots which act as conversational agents to answer user queries about legal and compliance matters. In the legal industry, AI chatbots have already begun transforming how professionals access and interpret information. For instance, Harvey AI, developed on OpenAI's GPT technology, has partnered with law firms and consulting giants such as PwC to assist in legal research, contract review, and compliance analysis (PwC announces strategic alliance with Harvey, positioning PwC's Legal Business Solutions at the forefront of legal generative AI, 2023). This growing adoption highlights the potential for AI to streamline legal workflows and enhance user understanding of complex legal texts.

% Similarly, there is growing recognition that such tools can extend to the data protection and compliance domain. Developments in this area align with Singapore's Smart Nation initiatives, which encourages the use of AI to improve governance, productivity, and security (AI for the Public Good For Singapore and the World, 2023). Therefore, AI-powered PDPA chatbots represent a promising approach to bridging compliance gaps, especially resource-constrained SMEs.

% \paragraph{Privacy and Data Protection Concerns in AI Chatbots.}

% AI chatbots introduce a range of privacy and data protection concerns, particularly when deployed in compliance-related environments. Large Language Models (LLMs) rely on vast amounts of training data and probabilistic generation techniques, which means they may inadvertently produce inaccurate, misleading, or hallucinated responses (Gültekin-Várkonyi, 2025). In legal and regulatory contexts, such errors carry heightened risks, as organisations may unknowingly act on incorrect information. Studies have shown that users often ascribe unwarranted authority to AI systems, further amplifying the potential for misinterpretation (Alkamli et al., 2024).

% A significant privacy risk lies in how chatbots process, store, or transmit user inputs. If poorly designed, chatbots may inadvertently retain personal information through server logs, analytics tools, or model telemetry, creating compliance obligations under data protection regimes such as the PDPA (PDPA Overview, n.d.). Research has highlighted that users frequently input sensitive identifiers—names, national IDs, contact details—into AI systems without understanding how the data will be used or stored (Sebastian, 2023). Such behaviour can expose organisations to liability, especially when combined with insufficiently transparent data handling practices.

% Another concern is the lack of jurisdictional awareness in generic AI models. Without explicit controls, chatbots may provide privacy guidance derived from other countries' regulatory frameworks, leading to inaccurate PDPA interpretations (Osborne Clarke, 2025). This issue was also observed in broader AI deployment studies, which noted that models trained on globally diverse datasets often generate advice incompatible with local regulatory requirements (KPMG, 2023).

% Furthermore, AI chatbots may amplify existing privacy risks by enabling large-scale, automated dissemination of erroneous information. As Marr (2025) notes, the conversational fluency of AI systems can mask underlying inaccuracies, making hallucinations particularly dangerous in compliance settings. These concerns reinforce the need for strict data minimisation, embedded refusal behaviour, jurisdiction-specific guardrails, and robust safeguards to ensure that AI chatbots do not themselves create new vectors of privacy or data protection risk.

% \paragraph{Retrieval-Augmented Generation.}

% Retrieval-Augmented Generation (RAG) has emerged as a key method for improving the factual accuracy, grounding, and explainability of LLM-based systems. Unlike standalone generative models, which rely solely on their pre-trained internal parameters, RAG enhances responses by retrieving relevant information from an external knowledge base and injecting it into the model's context window. This significantly reduces the likelihood of hallucination and supports transparency by grounding answers in verifiable sources (Hillebrand, 2025; Gültekin-Várkonyi, 2025).

% In regulatory domains, RAG is particularly advantageous. It ensures that generated responses are anchored in authorised documents such as PDPC guidelines, enforcement decisions, and advisory notes. This is critical in compliance settings, where organisations must rely on accurate, consistent, and up-to-date interpretations of legal obligations (Chasandras, 2025). RAG also supports modular and iterative updates to the system's knowledge base, allowing new or revised PDPC guidelines to be integrated without retraining the underlying model (Malali, 2025). This flexibility is essential in fast-evolving regulatory landscapes where interpretations and enforcement practices change over time.

% RAG also helps enforce jurisdictional boundaries. By constraining the retrieval corpus to Singapore-specific privacy documents, the system can avoid providing irrelevant or incorrect advice drawn from foreign regulatory frameworks—a frequent problem in non-RAG chatbot deployments (Osborne Clarke, 2025). This targeted retrieval thereby reduces compliance risks associated with general-purpose LLMs that lack built-in awareness of local laws.

% From a privacy perspective, RAG also supports controlled knowledge exposure. Since the retrieved documents are predefined and auditable, their use mitigates concerns regarding reliance on opaque or unpredictably trained model parameters. This aligns well with PDPA's emphasis on accuracy, minimization, and accountability.

% Overall, RAG provides a technologically robust foundation for AI-assisted PDPA guidance, combining the generative flexibility of LLMs with the factual reliability and explainability required in compliance-critical domains.
